{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting \n",
    "- 여러개의 약한 학습기를 순차적으로 학습시켜 예측하면서 잘 못 예측한 데이터에 가중치를 부여하여 오류를 개선해 나가며 학습하는 앙상블 모델 \n",
    "- 앞에서 학습한 모델 결과를 바탕으로 두 번째 모델에서 오류를 수정하는 방향으로 점진적으로 나가는 앙상블 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd \n",
    "data = pd.read_csv(\"../Data/breast-cancer-wisconsin.csv\", encoding=\"utf-8\")\n",
    "X = data.iloc[:, 1:10]\n",
    "y = data[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import * \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=410)\n",
    "\n",
    "from sklearn.preprocessing import * \n",
    "minmax = MinMaxScaler()\n",
    "minmax.fit(X_train)\n",
    "X_scaled_train = minmax.transform(X_train)\n",
    "X_scaled_test = minmax.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import * \n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=100, random_state=410)\n",
    "# n_estimator : 모델의 수행횟수 \n",
    "\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[333   0]\n",
      " [  0 179]] \n",
      "\n",
      "[[108   3]\n",
      " [  3  57]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import * \n",
    "con_train = confusion_matrix(y_train, pred_train)\n",
    "print(con_train, \"\\n\")\n",
    "\n",
    "con_test = confusion_matrix(y_test, pred_test)\n",
    "print(con_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       333\n",
      "           1       1.00      1.00      1.00       179\n",
      "\n",
      "    accuracy                           1.00       512\n",
      "   macro avg       1.00      1.00      1.00       512\n",
      "weighted avg       1.00      1.00      1.00       512\n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       111\n",
      "           1       0.95      0.95      0.95        60\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_train = classification_report(y_train, pred_train)\n",
    "print(report_train, \"\\n\")\n",
    "\n",
    "report_test = classification_report(y_test, pred_test)\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9765625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boost 앙상블 모델 적용\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=410, max_depth=1)\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9707602339181286"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[325   8]\n",
      " [  4 175]] \n",
      "\n",
      "[[109   2]\n",
      " [  3  57]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import * \n",
    "con_train = confusion_matrix(y_train, pred_train)\n",
    "print(con_train, \"\\n\")\n",
    "\n",
    "con_test = confusion_matrix(y_test, pred_test)\n",
    "print(con_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data2 = pd.read_csv(\"../Data/house_price.csv\", encoding=\"utf-8\")\n",
    "X = data2.iloc[:, 1:5]\n",
    "y = data2[['house_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import * \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=410)\n",
    "\n",
    "from sklearn.preprocessing import * \n",
    "minmax = MinMaxScaler()\n",
    "minmax.fit(X_train)\n",
    "X_scaled_train = minmax.transform(X_train)\n",
    "X_scaled_test = minmax.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46333184986225207"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostRegressor(n_estimators=100, random_state=410)\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47739677501438393"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 RMSE :  69500.48653917231\n",
      "테스트 데이터 RMSE :  70300.43621226118\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "\n",
    "print(\"학습 데이터 RMSE : \", np.sqrt(MSE_train))\n",
    "print(\"테스트 데이터 RMSE : \", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6184228916750144"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=410)\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.599890459947513"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 RMSE :  58603.842194636214\n",
      "테스트 데이터 RMSE :  61512.22414392499\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "\n",
    "print(\"학습 데이터 RMSE : \", np.sqrt(MSE_train))\n",
    "print(\"테스트 데이터 RMSE : \", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e56095587f6faaee8b6fe269bd4758f04d4dcfca17a97e0204e5c06e32115c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
